<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hanzhi Wang</title>
  
  <meta name="author" content="Hanzhi Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hanzhi Wang &nbsp / &nbsp 王涵之</name>
              </p>
              <p>I am currently a final year PhD candidate at School of Information, <a href="https://www.ruc.edu.cn/en">Renmin University of China</a>, where I am very fortunate to be advised by Prof. <a href="http://weizhewei.com/"><b>Zhewei Wei</b></a>.
              </p>
              <p> 
                Before that, I received my B.E. degree in Computer Science and Technology at School of Information, Renmin University of China in June 2019. 
              
                <!--
                I was a recepient of the 2022 Microsoft Research Asia Fellowship and the 2021 Baidu Scholarship.
                -->
                <!--
                At Google I've worked on <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
                I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>. 
                -->
              </p>
              <!--
              <p style="text-align:center">
                <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/jonbarron/">Github</a>
              </p>
              -->
              <p style="text-align:center">
                <a href="mailto:hanzhi_wang@ruc.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://github.com/wanghzccls/">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=ldG9drkAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a>
                <!--
                <a href="https://wanghzccls.github.io/CV/CV_HanzhiWang_20211018.pdf">CV</a> &nbsp/&nbsp
                <a href="https://wanghzccls.github.io/CV/CV_HanzhiWang_20211006_ch.pdf">简历</a>
                -->
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/Hanzhi_talk.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Hanzhi_talk.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research Interests</heading>
              <p>
                <!--I'm interested in graph algorithms and massive data algorithms. More precisely, my research focuses include: 
                <ul>
                  <li> efficient approximation of node proximities
                  <li> exact computation of single-source SimRank results
                  <li> theory on graph representation learning
                </ul>
                -->
              My research focuses on the development of provably-good scalable algorithms for graph data. In particular, I am interested in designing nearly linear or sub-linear time algorithms for large-scale graph analysis and learning problems.
              Specifically, my research can be categorized into three aspects:  
              <!--
              <li> efficient approximation of node proximities (e.g., PageRank)
              <li> efficient approximation of node similarities (e.g., SimRank)
              <li> scalable Graph Neural Networks (GNN) models
              -->
              <li> improving the computational complexities of various node proximity metrics, especially for PageRank, Personalized PageRank and Heat Kernel PageRank; 
              <li> designing algorithms for efficiently estimating the popular node similarity metric, SimRank, on large graphs;
              <li> designing scalable Graph Neural Network (GNN) models on large graphs. 
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <div class="list scroll">
            <p>
            [03/2024]  One paper was accepted to TKDE 2024. The paper's reviewing process spanned over one year, but very happily, it concluded with an encouraging outcome. Special thanks to Mingji!
            </p>

            <p>
            [02/2024]  One paper was accepted to STOC 2024. 
            </p>

            <p>
            [08/2023] I am attending VLDB 2023 in person to present our paper in Session G4 this Wednesday (Aug. 30th, 1:30 PM - 3:00 PM). Warmly welcome to stop by and chat with me!
            </p>
            
            <p>
            [08/2023] I was awarded a certificate of excellence in reviewing at KDD 2023.
            </p>
                
            <p>
            [05/2023] I will take an academic visit to The University of Melbourne (UoM) from June 2023, advised by <a href="https://sites.google.com/site/junhogan/"><b>Dr. Junhao Gan</b></a>.
            </p>

            <p>
            [05/2023]  One paper, with a focus on the single-node PageRank computation, was accepted to VLDB 2023. 
            </p>
            
            <p>
            [05/2023] One paper was accepted to KDD 2023 with the rating of 'Accept' across the board (4/4/4/4). We appreciate the recognition from all the anonymous reviewers! 
            </p>

            <p>
            [12/2022] I will spend a couple of months at National University of Singapore (NUS) as an exchange student under the supervision of <a href="https://www.comp.nus.edu.sg/~xiaoxk/"><b>Prof. Xiaokui Xiao</b></a>.
            </p>

            <!--
            <p>
            [04/2023] I serve as PC Member for NeurIPS 2023.
            </p>

            <p>
            [01/2023] I serve as PC Member for KDD 2023.
            </p>
            
            <p>
            [12/2022] I have submitted my Ph.D. Thesis Proposal and start to work on my Ph.D. thesis. How time flies!
            </p>
 
            <p>
            [10/2022] I am honored to be awarded the 2022 Microsoft Research Asia Fellowship, which is only given to 12 Ph.D. students majoring in computer science in the Asia-Pacific region.
            </p>

            <p>
            [12/2021] I am fortunate to receive the 2021 Baidu Scholarship, which is only awarded 10 Chinese students majoring in artificial intelligence and related areas in the world.  
            </p>

            <p>
            [12/2021] I passed my Ph.D. quantify exam and now become a Ph.D. candidate :)
            </p>
            --> 

            </div>
          </td>
        </tr>
      </tbody></table>
      


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <!-- <p>
              Note: Authors marked with * are the corresponding authors.
              </p> -->
              <p>
              Note: Papers marked with <span class="style_1">†</span> use alphabetic ordering of authors, following the convention of theoretical computer science.
              </p>
              
              <a href="https://wanghzccls.github.io/">
                <papertitle>Revisiting Local Computation of PageRank: Simple and Optimal. </papertitle><span class="style_1">†</span>
                </a>
                <br>
                <strong>Hanzhi Wang</strong>,
                Zhewei Wei, 
                Ji-Rong Wen, 
                Mingji Yang
                <br>
                <em>STOC</em>, 2024
                <br>

                <a href="https://arxiv.org/pdf/2403.12648.pdf">Technical Report</a>
  
                <p></p>
                <p>We establish matching upper and lower bounds for the worst-case computational complexity of single-node PageRank computation on directed graphs. Additionally, for the celebrated ApproxContributions algorithm (also known as Backward Push or Local Push, proposed by Andersen, Borgs, Chayes, Hopcroft, Mirrokni, and Teng in WAW 2007), we upper bound its worst-case computational complexity on directed graphs and prove its optimality by establishing a matching lower bound. </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/abstract/document/10471277">
                  <papertitle>Efficient Algorithms for Personalized PageRank Computation: A Survey. </papertitle>
                  </a>
                  <br>
                  Mingji Yang, 
                  <strong>Hanzhi Wang</strong>,
                  Zhewei Wei, 
                  Sibo Wang, 
                  Ji-Rong Wen
                  <br>
                  <em>TKDE</em>, 2024
                  <br>
                  
                  <a href="https://arxiv.org/pdf/2403.05198.pdf">Technical Report</a>

                  
    
                  <p></p>
                  <p>We recap several frequently used techniques for Personalized PageRank (PPR) computation and conduct a comprehensive survey of various recent PPR algorithms from an algorithmic perspective. </p>
                </td>
          </tr>

            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://www.vldb.org/pvldb/vol16/p2949-wang.pdf">
                  <papertitle>Estimating Single-Node PageRank in O(min(d<sub>t</sub>, m<sup>1/2</sup>))</span> Time. </papertitle>
                  </a>
                  <br>
                  <strong>Hanzhi Wang</strong>,
                  Zhewei Wei
                  <br>
                  <em>VLDB</em>, 2023
                  <br>
                  
                  <a href="https://arxiv.org/pdf/2307.13162.pdf">Technical Report</a>
                  /
                  <a href="https://github.com/wanghzccls/SetPush-code">code</a>
                  /
                  <a href="https://wanghzccls.github.io/slides/SetPush.pptx">slide</a>
                  /
                  <a href="https://wanghzccls.github.io/poster/VLDB23_SetPush.pdf">poster</a>

                  
    
                  <p></p>
                  <p>For the problem of estimating a single node's PageRank score in an undirected graph, we tighten the upper bound for query time complexity from O((nd<sub>t</sub>)<sup>1/2</sup>) to O(min(d<sub>t</sub>, m<sup>1/2</sup>)) (omitting logarithmic factors). Here n and m denote the number of nodes and edges in the given graph, respectively. d<sub>t</sub> denotes the degree of the given target node t. </sub></p>
                </td>
          </tr>

            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3580305.3599458">
              <papertitle>Optimal Dynamic Subset Sampling: Theory and Applications.</papertitle>
              </a>
              <br>
              Lu Yi,
              <strong>Hanzhi Wang</strong>,
              Zhewei Wei
              <br>
              <em>KDD</em>, 2023
              <br>
              
              <a href="https://arxiv.org/pdf/2305.18785.pdf">Technical Report</a>
              /
              <a href="https://wanghzccls.github.io/slides/KDD23_ODSS.pptx">slide</a>
              /
              <a href="https://wanghzccls.github.io/poster/KDD23_ODSS.pdf">poster</a>

              <p></p>
              <p>We study the fundamental problem of sampling indepedent events (called subset sampling) in a dynamic setting. We present the <em>ODSS</em> algorithm, which is the first to achieve the optimal time complexity per sample and per update simultaneously. </p>
            </td>
          </tr>

            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.14778/3523210.3523216">
              <papertitle>Edge-based Local Push for Personalized PageRank.</papertitle>
              </a>
              <br>
              <strong>Hanzhi Wang</strong>,
              Zhewei Wei,
              Junhao Gan, 
              Ye Yuan, 
              Xiaoyong Du, 
              Ji-Rong Wen
              <br>
              <em>VLDB</em>, 2022
              <br>

              <a href="https://arxiv.org/pdf/2203.07937.pdf">Technical Report</a>
              /
              <a href="https://github.com/wanghzccls/EdgePush">code</a>
              /
              <a href="https://wanghzccls.github.io/slides/EdgePush_presentation_final.pptx">slide</a>

              <p></p>
              <p>The state-of-the-art algorithm, LocalPush, for Personalized PageRank computation can be rather inefficient on weighted graphs. In this paper, we propose an <em>Edge-based Push Method (EdgePush)</em>, which decomposes the push operation of LocalPush into separate edge-based push operations and achieves superior query efficiency over LocalPush on weighted graphs.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3534678.3539352">
              <papertitle>Instant Graph Neural Networks for Dynamic Graphs.</papertitle>
              </a>
              <br>
              Yanping Zheng, 
              <strong>Hanzhi Wang</strong>,
              Zhewei Wei,
              Jiajun Liu, 
              Sibo Wang
              <br>
              <em>KDD</em>, 2022
              <br>

              <a href="https://arxiv.org/pdf/2206.01379.pdf">Technical Report</a>
              /
              <a href="https://github.com/zheng-yp/InstantGNN">code</a>
              


              <p></p>
              <p>We propose <em>Instant Graph Neural Network (InstantGNN)</em>, an incremental computation approach to support instant updates of graph representation results on dynamic graphs.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3447548.3467243">
              <papertitle>Approximate Graph Propagation</papertitle>
              </a>
              <br>
              <strong>Hanzhi Wang</strong>,
              Mingguo He,
              Zhewei Wei,
              Sibo Wang, 
              Ye Yuan, 
              Xiaoyong Du, 
              Ji-Rong Wen
              <br>
              <em>KDD</em>, 2021
              <br>

              <a href="https://arxiv.org/pdf/2106.03058.pdf">Technical Report</a>
              /
              <a href="https://github.com/wanghzccls/AGP-Approximate_Graph_Propagation">code</a>
              /
              <a href="https://wanghzccls.github.io/slides/AGP_KDD'21_pre_final.pptx">slide</a>
              /
              <a href="https://wanghzccls.github.io/poster/KDD21_AGP.pdf">poster</a>

              <p></p>
              <p>We propose <em>Approximate Graph Propagation (AGP)</em>, a unified randomized algorithm that computes various proximity queries and GNN feature propagation in almost optimal time complexity.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <!--
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfbake_160.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>

            -->  
              <a href="https://link.springer.com/article/10.1007/s00778-021-00672-7">
              <papertitle>ExactSim: benchmarking single-source SimRank algorithms with high-precision ground truths</papertitle>
              </a>
              <br>
              <strong>Hanzhi Wang</strong>,
              Zhewei Wei,
              Yu Liu, 
              Ye Yuan, 
              Xiaoyong Du, 
              Ji-Rong Wen
              <br>
              <em>VLDB Journal</em>, 2021
              <br>
              <!--
              <a href="http://nerf.live">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.14645">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">video</a>
              /
              <a href="https://nerf.live/#demos">demo</a>
              --> 
              <p></p>
              <p>This work is an extended version of the conference paper "Exact Single-Source SimRank Computation on Large Graphs" accepted by SIGMOD 2020. With the ground truths computed by <em>ExactSim</em>, we conduct the first experimental study of the accuracy/cost trade-offs of existing approximate SimRank algorithms on large graphs.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <!--
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfbake_160.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>

            -->  
              <a href="https://dl.acm.org/doi/10.1145/3394486.3403108">
              <papertitle>Personalized PageRank to a Target Node, Revisited</papertitle>
              </a>
              <br>
              <strong>Hanzhi Wang</strong>,
              Zhewei Wei,
              Junhao Gan, 
              Sibo Wang, 
              Zengfeng Huang
              <br>
              <em>KDD</em>, 2020
              <br>

              <a href="https://arxiv.org/pdf/2006.11876.pdf">Technical Report</a>
              /
              <a href="https://github.com/wanghzccls/RBS">code</a>
              /
              <a href="https://wanghzccls.github.io/slides/RBS_KDD'20.pptx">slide</a>
              <p></p>
              <p>We propose <em>Randomized Backward Search (RBS)</em>, a novel algorithm that answers approximate single-target personalized PageRank queries (also known as PageRank contribution queries) with near optimal time complexity. </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <!--
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfbake_160.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>

            -->  
              <a href="https://dl.acm.org/doi/10.1145/3318464.3389781">
              <papertitle>Exact Single-Source SimRank Computation on Large Graphs</papertitle>
              </a>
              <br>
              <strong>Hanzhi Wang</strong>,
              Zhewei Wei,
              Ye Yuan, 
              Xiaoyong Du, 
              Ji-Rong Wen
              <br>
              <em>SIGMOD</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2004.03493.pdf">Technical Report</a>
              /
              <a href="https://github.com/wanghzccls/ExactSim">code</a>
              /
              <a href="https://wanghzccls.github.io/slides/ExactSim_SIGMOD'20.pptx">slide</a>
              <p></p>
              <p>We propose <em>ExactSim</em>, the first algorithm that enables probabilistic exact single-source SimRank queries on large graphs. ExactSim can provide the ground truth with a precision up to 7 decimal places for single-source SimRank queries on large graphs within a reasonable query time.</p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Patents</heading>
              <br>
              
              <br>A Friend Recommendation Method based on Personalized PageRank 
              <br> (一种基于个性化佩奇排名的好友推荐方法)
                <br>
                Zhewei Wei, 
                <strong>Hanzhi Wang</strong>,
                Junhao Gan, 
                Sibo Wang,  
                Zengfeng Huang
                <br>
                <em>Chinese National Patent</em>, ZL202010850777.2

              <p>
              </p>

              <br>A Friend Recommendation Method based on the Exact Results of Single-Source SimRank 
              <br> (基于单源SimRank精确解的好友推荐方法)
                
                
                <br>
                Zhewei Wei, 
                <strong>Hanzhi Wang</strong>,
                Ye Yuan, 
                Ji-Rong Wen,  
                Xiaoyong Du
                <br>
                <em>Chinese National Patent</em>, ZL202010536506.X

              <p>
              </p>
              
              <!--
              <papertitle>A Single-Source SimRank based Method for Collaborative Filtering Recommendation 
              <br> (基于单源SimRank的协同过滤推荐方法)
              </papertitle>
               --> 

              <br> A Collaborative Filtering Recommendation Method based on Single-Source SimRank Results
              <br> (基于单源SimRank的协同过滤推荐方法)
              
              <br>
              Zhewei Wei, 
              Xiaodong He, 
              <strong>Hanzhi Wang</strong>,
              Xiaokui Xiao, 
              Sibo Wang, 
              Yu Liu, 
              Xiaoyong Du
              <br>
              <em>Chinese National Patent</em>, ZL201910577524.X

              

            </td>
          </tr>

          
        </tbody></table>


        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
              <heading>Honors and Awards</heading>
              <ul></ul>
              <li>
              Certified Excellence in Reviewing for KDD 2023.
              <ul></ul>
              <li> <strong><a href="https://www.microsoft.com/en-us/research/academic-program/fellowships-microsoft-research-asia/">Microsoft Research Asia Fellowship</a></strong>, 2022 <strong>(awarded to twelve PhD students in the Asia-Pacific region)</strong>. 
              <ul> </ul>
              <li> <strong><a href="http://scholarship.baidu.com">Baidu Scholarship</a></strong>, 2021 <strong>(awarded to ten Chinese students worldwide)</strong>.
              <ul></ul>
              <li> National Scholarship, 2021. 
              <ul></ul>
              <li> The Outstanding Innovative Talents Cultivation Funded Programs of Renmin University of China, 2020. 
              <ul></ul>
              <li> China National Petroleum Corporation (CNPC) Scholarship, 2020. 
            </td>
          </tr>
        </table>

        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
          <td width="100%" valign="middle">
            <heading>Academic Services</heading>
             <ul></ul>
              <p>PC member/Reviewer:</p>
                <li>Annual Conference on Neural Information Processing Systems (NeurIPS), 2023 </li>
                <li>International Conference on Knowledge Discovery and Data Mining (KDD), 2023/2024</li>
                <li>International Conference on Learning Representations (ICLR), 2024</li>
                <li>ACM International Conference on Web Search and Data Mining (WSDM), 2023/2024</li>
                <li>SIAM International Conference on Data Mining (SDM), 2024</li>
                <li>Australasian Database Conference (ADC), 2023</li>
                <li>IEEE Communications Magazine</li>
                <li>Information Retrieval Journal </li>
                <li>International Conference on Machine Learning (ICML), 2022</li>
          </td>
        </tr>
      </table>
      



        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            <td width="100%" valign="middle">
            <heading>Invited Talks</heading>
            <ul></ul>
            <papertitle>Approximate Graph Propagation. </papertitle>
                  <a href="https://wanghzccls.github.io/slides/Aminer_AGP_final.pptx">[slide]</a>
                    <br><em>AMiner </em>
                    <br>Online, Oct. 2021
            <ul></ul>
              
            <papertitle>Efficient Computation of Random Walk and the Applications in Graph Representation Learning. </papertitle>
                    <a href="https://wanghzccls.github.io/slides/DataFun_KDD'21_final.pptx">[slide]</a>
                      <br><em>DataFun </em>
                      <br>Online, Aug. 2021
            <ul></ul>
              
            <papertitle>A Near Optimal Algorithm for Single-Target Personalized PageRank. </papertitle>
                  <a href="https://wanghzccls.github.io/slides/SMP_KDD20_final.pptx">[slide]</a>
                      <br>The 9th National Social Media Processing Conference (<em>SMP</em>,  2020)
                      <br>Online, Sept. 2020
            


              <p></p>
            </td>
          </tr> 

        </table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                  Last update: Mar. 2024 &nbsp&nbsp&nbsp&nbsp <a href="https://jonbarron.info/">Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
